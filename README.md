# NOV25 ‚Äì BDE Satisfaction Client

üöÄ Pr√©sentation du projet

Cette plateforme permet d‚Äôautomatiser l‚Äôanalyse de la satisfaction client √† partir d‚Äôavis en ligne.
Elle couvre l‚Äôensemble de la cha√Æne data engineering & machine learning, de la collecte des donn√©es jusqu‚Äô√† leur exposition via une API et une interface de visualisation interactive.

Le projet a √©t√© r√©alis√© dans le cadre du Bootcamp Data Engineer ‚Äì DataScientest, avec une approche agile, orient√©e scalabilit√©, automatisation et observabilit√©.

üéØ Objectifs

- Collecter automatiquement des avis clients √† grande √©chelle
- Analyser le sentiment des avis via un mod√®le de Machine Learning / NLP
- Stocker et indexer les donn√©es dans une architecture NoSQL
- Exposer les donn√©es via une API REST
- Proposer des dashboards interactifs pour l‚Äôexploration des r√©sultats
- Mettre en place orchestration, monitoring et d√©ploiement conteneuris√©

üèóÔ∏è Architecture du projet

![Sch√©ma d'architecture du projet](images/architecture_projet_satisfaction_client.png)

üîÑ Pipeline ETL ‚Äì Avis clients ‚Üí Elasticsearch

Ce d√©p√¥t contient un pipeline ETL (Extract ‚Äì Transform ‚Äì Load) permettant de collecter des avis clients et de les indexer dans Elasticsearch (indice `reviews`).

üîπ Extraction

- Collecte des avis pour une ou plusieurs entreprises (une entreprise dans ce projet)
- Gestion automatique de la pagination
- Validation et filtrage initial des donn√©es

üîπ Transformation

- Anonymisation des donn√©es sensibles (conformit√© RGPD)
- Nettoyage et normalisation des textes
- Parsing et standardisation des dates
- Enrichissement et structuration des documents pour Elasticsearch

üîπ Chargement

- Indexation via op√©rations bulk pour de meilleures performances
- M√©canisme d‚Äôupsert pour √©viter les doublons
- Logs d√©taill√©s et gestion des erreurs pour le suivi du pipeline

üê≥ Environnement Docker & Services

L‚Äôensemble du projet est d√©ploy√© via Docker Compose, garantissant la portabilit√© et l‚Äôisolation des services.

| Service          | R√¥le                                                        |
|------------------|-------------------------------------------------------------|
| **Airflow**      | Orchestration et planification des DAGs ETL                 |
| **FastAPI**      | API REST pour l‚Äôacc√®s aux donn√©es et r√©sultats d‚Äôanalyse    |
| **Streamlit**    | Interface utilisateur et dashboards interactifs             |
| **Elasticsearch**| Stockage, recherche et agr√©gation des avis                  |
| **Kibana**       | Exploration et visualisation des donn√©es Elasticsearch      |
| **Prometheus**   | Collecte des m√©triques applicatives                         |
| **Grafana**      | Monitoring et dashboards de supervision                     |
| **Node Exporter**| Collecte des m√©triques syst√®me                              |

üß∞ Stack technique

- Langage : Python
- Data Engineering : Airflow, ETL, Elasticsearch
- Machine Learning / NLP : Analyse de sentiment
- Backend : FastAPI
- Frontend : Streamlit
- Conteneurisation : Docker, Docker Compose
- Observabilit√© : Prometheus, Grafana

üë• √âquipe projet

ibbouM  
roxfr Thierry M  
SofianeDore

---

## Table des mati√®res

1. [Pr√©requis](#1-pr√©requis)
2. [Configuration et ex√©cution locale](#2-configuration-et-ex√©cution-locale)
3. [Tests Unitaires](#3-tests-unitaires)
4. [Ex√©cution avec Docker Compose](#4-ex√©cution-avec-docker-compose)
5. [Cr√©ation d‚Äôune vue et d‚Äôun tableau de bord dans ES/Kibana](#5-cr√©ation-dune-vue-et-dun-tableau-de-bord-dans-es-kibana)
6. [Acc√®s √† Streamlit](#6-acc√®s-√†-streamlit)
7. [Acc√®s √† Apache Airflow](#7-acc√®s-√†-apache-airflow)
8. [Acc√®s √† Prometheus/Grafana](#8-acc√®s-√†-prometheus-grafana)
9. [Acc√®s √† FastAPI (docs)](#9-acc√®s-√†-fastapi-docs)
10. [D√©pannage & probl√®mes fr√©quents](#10-d√©pannage--probl√®mes-fr√©quents)

---

## 1. Pr√©requis

| Outil          | Version | Obligatoire |
| -------------- | ------- | ----------- |
| Python         | 3.10+   | ‚úÖ         |
| Docker         | 20.x+   | ‚úÖ         |
| Docker Compose | 2.20+   | ‚úÖ         |
| Elasticsearch  | 8.12    | optionnel  |
| Kibana         | 8.12    | optionnel  |
|**WSL Ubuntu**  | 2.6+    | ‚úÖ         |

---

## 2. Configuration et ex√©cution locale

### 2.1. Cr√©ation de l‚Äôenvironnement virtuel

   ```bash
   # Sous WSL Ubuntu depuis la racine du projet
   python3 -m venv venv
   source venv/bin/activate
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

---

## 3. Tests Unitaires

Les tests du projet sont r√©alis√©s avec pytest.</br>
Pour ex√©cuter tous les tests, il suffit de se rendre √† la racine du projet et</br>
de lancer la commande suivante :

   ```bash
   # Sous WSL Ubuntu depuis la racine du projet
   source venv/bin/activate
   export PYTHONPATH=$(pwd)/src
   echo $PYTHONPATH
   pytest src/tests
   ```

---

## 4. Ex√©cution avec Docker Compose

‚ö†Ô∏è **Attention** :</br>
   - Les commandes ci-dessous suppriment tous les conteneurs, images et volumes Docker li√©s au stack, et r√©initialise toutes les donn√©es persistantes.
Utilisez-la uniquement si vous voulez repartir compl√®tement √† z√©ro ou pour votre premi√®re ex√©cution du stack.

   - Si ce script est modifi√© sous Windows (VS Code),
ex√©cuter `dos2unix start_stack.sh` avant de lancer le script

   ```bash
   cd src/docker
   docker volume prune -f
   docker image prune -a -f
   docker network prune -f
   docker container prune -f
   docker system prune -a -f --volumes
   docker-compose down --volumes --rmi all --remove-orphans
   docker buildx prune -a -f
   ```

   ```bash
   # Docker Desktop doit √™tre d√©marr√©
   # Depuis la racine du projet

   # WSL Ubuntu (terminal)
   cd src/docker
   chmod +x start_stack.sh
   ./start_stack.sh

   # Windows (PowerShell admin)
   cd src\docker
   Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass
   .\start_stack.ps1
   ```

---

## 5. Cr√©ation d‚Äôune vue et d‚Äôun tableau de bord dans ES/Kibana

### 5.1. Acc√®s √† ES/Kibana

   ```bash
   http://localhost:5601
   ```

### 5.2. V√©rification des donn√©es

Depuis ES/Kibana ‚Äì Dev Tools :

   ```bash
   # Liste tous les indices
   GET /_cat/indices?v
   # Voir le mapping d'un index
   GET /reviews/_mapping
   # Compter le nombre de documents
   GET /reviews/_count
   # R√©cup√©re tous les documents
   GET /reviews/_search
   {
      "query": {
         "match_all": {}
      }
   }
   # R√©cup√©re les 3 derni√®res reviews les plus r√©cents
   GET reviews/_search
   {
      "size": 3,
      "sort": [
         { "id_review": { "order": "desc" } }
      ]
   }
   ```

<img src="images/es-kibana_dev_tools.png" width="70%">

### 5.3. Cr√©ation d‚Äôune Data View

   ```bash
   Nom : NOV25_BDE_SATISFACTION_CLIENT
   Index pattern : reviews*
   Champ temporel : Aucun
   ```

### 5.4. Visualisation

1. Acc√©der √† Elastic/Kibana depuis le navigateur : http://localhost:5601/app/home#/

2. Aller dans **Visualize Library** ‚Üí **Create new visualization**

3. S√©lectionner le type de visualisation : **Lens**

4. Choisir la **Data View** pr√©c√©demment cr√©√©e (`NOV25_BDE_SATISFACTION_CLIENT`)

5. Cr√©er les visualisations suivantes :

   - **Histogramme des notes** (r√©partition des avis par score)
   - **Top cat√©gories** (cat√©gories les plus repr√©sent√©es)
   - **Volume d‚Äôavis** (nombre total d‚Äôavis ou √©volution)

6. Enregistrer chaque visualisation pour pouvoir les r√©utiliser dans un tableau de bord.

---

## 6. Acc√®s √† Streamlit

   ```bash
   http://localhost:8501
   ```

   - Identifiant  : admin</br>
   - Mot de passe : admin

<img src="images/streamlit_connexion.png" width="40%">

---

## 7. Acc√®s √† Apache Airflow

   ```bash
   http://localhost:8081/login/
   ```

   - Identifiant  : admin</br>
   - Mot de passe : admin

<img src="images/airflow_connexion.png" width="70%">
<img src="images/airflow_dag.png" width="70%">
<img src="images/airflow_graph.png" width="70%">

---

## 8. Acc√®s √† Prometheus/Grafana

- Prometheus :

   ```bash
   http://localhost:9090/targets
   ```

- Grafana :

   ```bash
   http://localhost:3000
   ```

   - Identifiant  : admin</br>
   - Mot de passe : admin

<img src="images/grafana_connexion.png" width="70%">
<img src="images/grafana_dashboard.png" width="70%">

---

## 9. Acc√®s √† FastAPI (docs)

- Prometheus :

   ```bash
   http://localhost:8000/docs
   ```

<img src="images/fastapi_docs.png" width="70%">

---

## 10. D√©pannage & probl√®mes fr√©quents

| Probl√®me                  | Cause probable                   | Solution                                               |
| ------------------------- | -------------------------------- | ----------------------------------------------------- |
| ES ne d√©marre pas          | Port 9200 utilis√©, m√©moire faible | V√©rifier ports et ajuster `docker-compose.yml`       |
| ConnectionError ES         | Service ES pas encore pr√™t       | Attendre 30s ou ajouter un retry                     |
| Mapping non appliqu√©       | Indice existant                  | Supprimer l‚Äôindice : `DELETE /reviews`              |
| Data View introuvable      | Mauvais pattern                  | V√©rifier que le pattern est `reviews*`              |
| Probl√®me de permissions    | Volume Docker                    | `chmod -R 777 ./data`                                |
| Docker sous Windows        | Docker Desktop ou WSL2 inactif   | V√©rifier Docker Desktop et WSL2, puis relancer      |
| Invalid char '/' config.json | `~/.docker/config.json` invalide | Supprimer tout commentaire et garder `{ "auths": {} }` |
| WSL + Docker login √©choue  | Credential helper mal configur√© | Supprimer entr√©es invalides, garder `{ "auths": {} }`, refaire `docker login` |
