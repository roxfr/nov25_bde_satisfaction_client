# NOV25 ‚Äì Plateforme d‚Äôanalyse de la satisfaction client

## üöÄ Pr√©sentation

Cette plateforme permet d‚Äôautomatiser l‚Äôanalyse de la satisfaction client √† partir d‚Äôavis en ligne, depuis la collecte des donn√©es brutes jusqu‚Äô√† leur exploitation via une API et des tableaux de bord interactifs.

Le projet met en ≈ìuvre une **cha√Æne Data Engineering compl√®te**, con√ßue pour √™tre **scalable, observable et automatis√©e**, couvrant l‚Äôensemble du cycle de vie des donn√©es : ingestion, transformation, enrichissement, stockage, exposition et supervision.

Il a √©t√© r√©alis√© dans le cadre du **Bootcamp Data Engineer ‚Äì DataScientest**, en adoptant une approche proche d‚Äôun contexte professionnel (pipeline orchestr√©, conteneurisation, CI/CD, monitoring).

---

## üéØ Contexte & cas d‚Äôusage (simul√©)

Une entreprise souhaite centraliser et analyser automatiquement les avis clients publi√©s en ligne afin de :

- suivre l‚Äô√©volution de la satisfaction client dans le temps,
- identifier rapidement les points de friction ou d‚Äôinsatisfaction,
- fournir des indicateurs exploitables aux √©quipes m√©tier et produit,
- disposer d‚Äôune solution automatis√©e et supervis√©e, limitant les traitements manuels.

La solution propos√©e automatise l‚Äôensemble du flux de donn√©es, depuis la collecte des avis jusqu‚Äô√† leur visualisation et leur exposition via des API.

---

## üéØ Objectifs du projet

- Collecter automatiquement des avis clients √† grande √©chelle
- Nettoyer, standardiser et anonymiser les donn√©es (conformit√© RGPD)
- Enrichir les avis par une analyse de sentiment (NLP)
- Stocker et indexer les donn√©es dans une base NoSQL orient√©e recherche
- Exposer les donn√©es via une API REST document√©e
- Mettre √† disposition des dashboards interactifs pour l‚Äôanalyse
- Orchestrer, monitorer et d√©ployer l‚Äôensemble du pipeline de mani√®re fiable

---

## üîÑ Pipeline ETL ‚Äì De la collecte √† l‚Äôindexation

### Extraction (EXTRACT)

- Collecte automatis√©e des avis clients via un processus de scraping
- Gestion de la pagination et validation des donn√©es
- Export des donn√©es au format **JSON brut**, conservant l‚Äôensemble des informations originales

### Transformation (TRANSFORM)

- Nettoyage et standardisation des donn√©es textuelles
- Anonymisation des informations sensibles
- Analyse de sentiment pour classifier les avis (positif, n√©gatif, neutre)
- Enregistrement des donn√©es transform√©es au format **JSONL**, adapt√© au traitement de volumes importants

### Chargement (LOAD)

- Chargement des donn√©es dans une base **NoSQL (Elasticsearch)**
- Utilisation d‚Äôun m√©canisme d‚Äô**upsert** afin de garantir une base coh√©rente et √† jour
- Journalisation d√©taill√©e et gestion des erreurs pour le suivi du pipeline

Ce pipeline permet de transformer des avis clients bruts en **donn√©es structur√©es, enrichies et exploitables**.

---

## ‚è±Ô∏è Orchestration & automatisation

Le pipeline ETL est orchestr√© √† l‚Äôaide d‚Äô**Apache Airflow**, qui organise les diff√©rentes √©tapes sous forme de **DAG (Directed Acyclic Graph)**.

Les principaux b√©n√©fices :

- Vision globale du pipeline et de l‚Äôencha√Ænement des t√¢ches
- Suivi pr√©cis des statuts (success, running, failed)
- Acc√®s d√©taill√© aux logs pour le diagnostic des erreurs
- Possibilit√© de d√©clencher, suspendre ou relancer le pipeline manuellement
- Planification automatique des traitements selon un calendrier d√©fini

---

## üìä Acc√®s aux donn√©es & visualisation

Les r√©sultats sont accessibles via :

- une **API REST FastAPI**, permettant l‚Äôexposition des donn√©es et des r√©sultats d‚Äôanalyse,
- des **dashboards Kibana**, int√©gr√©s directement dans l‚Äôinterface **Streamlit** via iframe.

Cette int√©gration offre :

- un point d‚Äôacc√®s unique pour l‚Äôensemble des indicateurs,
- une navigation simple et fluide pour les utilisateurs,
- une visualisation interactive facilitant l‚Äôexploration des avis et des sentiments associ√©s.

Ces outils permettent aux √©quipes **business** et **produit** d‚Äôidentifier rapidement les leviers d‚Äôam√©lioration et de prioriser les actions.

---

## üìà Supervision & observabilit√©

La plateforme int√®gre une couche de monitoring pour suivre le pipeline ETL et l‚Äô√©tat du syst√®me :

- **Airflow** pour l‚Äôorchestration des workflows, permettant de visualiser le statut des t√¢ches et la date de derni√®re ex√©cution
- **Prometheus** pour la collecte de m√©triques applicatives et syst√®me
- **Grafana** pour la visualisation de ces m√©triques (tableaux de bord pr√™ts √† personnaliser selon les besoins)
- **Node Exporter** pour l‚Äôacc√®s aux m√©triques syst√®me

> Les indicateurs r√©ellement suivis dans le projet incluent le statut des workflows ETL et la date de derni√®re ex√©cution.  
> Grafana et Prometheus permettent de pr√©parer facilement la supervision des ressources et de la disponibilit√© en production.


---

## üèóÔ∏è Architecture globale du projet

![Sch√©ma d'architecture du projet](images/architecture_projet_satisfaction_client.png)

üîÑ Pipeline ETL ‚Äì Avis clients ‚Üí Elasticsearch

Ce d√©p√¥t contient un pipeline ETL (Extract ‚Äì Transform ‚Äì Load) permettant de collecter des avis clients et de les indexer dans Elasticsearch (indice `reviews`).

üîπ Extraction

- Collecte des avis pour une ou plusieurs entreprises (une entreprise dans ce projet)
- Gestion automatique de la pagination
- Validation et filtrage initial des donn√©es

üîπ Transformation

- Anonymisation des donn√©es sensibles (conformit√© RGPD)
- Nettoyage et normalisation des textes
- Parsing et standardisation des dates
- Enrichissement et structuration des documents pour Elasticsearch

üîπ Chargement

- Indexation via op√©rations bulk pour de meilleures performances
- M√©canisme d‚Äôupsert pour √©viter les doublons
- Logs d√©taill√©s et gestion des erreurs pour le suivi du pipeline

üê≥ Environnement Docker & Services

L‚Äôensemble du projet est d√©ploy√© via Docker Compose, garantissant la portabilit√© et l‚Äôisolation des services.

| Service          | R√¥le                                                        |
|------------------|-------------------------------------------------------------|
| **Airflow**      | Orchestration et planification des DAGs ETL                 |
| **FastAPI**      | API REST pour l‚Äôacc√®s aux donn√©es et r√©sultats d‚Äôanalyse    |
| **Streamlit**    | Interface utilisateur et dashboards interactifs             |
| **Elasticsearch**| Stockage, recherche et agr√©gation des avis                  |
| **Kibana**       | Exploration et visualisation des donn√©es Elasticsearch      |
| **Prometheus**   | Collecte des m√©triques applicatives                         |
| **Grafana**      | Monitoring et dashboards de supervision                     |
| **Node Exporter**| Collecte des m√©triques syst√®me                              |

üß∞ Stack technique

- Langage : Python
- Data Engineering : Airflow, ETL, Elasticsearch
- Machine Learning / NLP : Analyse de sentiment
- Backend : FastAPI
- Frontend : Streamlit
- Conteneurisation : Docker, Docker Compose
- Observabilit√© : Prometheus, Grafana

üë• √âquipe projet

ibbouM  
roxfr Thierry M  
SofianeDore

---

## Table des mati√®res

1. [Pr√©requis](#1-pr√©requis)
2. [Configuration et ex√©cution locale](#2-configuration-et-ex√©cution-locale)
3. [Tests Unitaires](#3-tests-unitaires)
4. [Ex√©cution avec Docker Compose](#4-ex√©cution-avec-docker-compose)
5. [Cr√©ation d‚Äôune vue et d‚Äôun tableau de bord dans ES/Kibana](#5-cr√©ation-dune-vue-et-dun-tableau-de-bord-dans-es-kibana)
6. [Acc√®s √† Streamlit](#6-acc√®s-√†-streamlit)
7. [Acc√®s √† Apache Airflow](#7-acc√®s-√†-apache-airflow)
8. [Acc√®s √† Prometheus/Grafana](#8-acc√®s-√†-prometheus-grafana)
9. [Acc√®s √† FastAPI (docs)](#9-acc√®s-√†-fastapi-docs)
10. [D√©pannage & probl√®mes fr√©quents](#10-d√©pannage--probl√®mes-fr√©quents)

---

## 1. Pr√©requis

| Outil          | Version | Obligatoire |
| -------------- | ------- | ----------- |
| Python         | 3.10+   | ‚úÖ         |
| Docker         | 20.x+   | ‚úÖ         |
| Docker Compose | 2.20+   | ‚úÖ         |
| Elasticsearch  | 8.12    | optionnel  |
| Kibana         | 8.12    | optionnel  |
|**WSL Ubuntu**  | 2.6+    | ‚úÖ         |

---

## 2. Configuration et ex√©cution locale

### 2.1. Cr√©ation de l‚Äôenvironnement virtuel

   ```bash
   # Sous WSL Ubuntu depuis la racine du projet
   python3 -m venv venv
   source venv/bin/activate
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

---

## 3. Tests Unitaires

Les tests du projet sont r√©alis√©s avec pytest.</br>
Pour ex√©cuter tous les tests, il suffit de se rendre √† la racine du projet et</br>
de lancer la commande suivante :

   ```bash
   # Sous WSL Ubuntu depuis la racine du projet
   source venv/bin/activate
   export PYTHONPATH=$(pwd)/src
   echo $PYTHONPATH
   pytest src/tests
   ```

---

## 4. Ex√©cution avec Docker Compose

‚ö†Ô∏è **Attention** :</br>
   - Les commandes ci-dessous suppriment tous les conteneurs, images et volumes Docker li√©s au stack, et r√©initialise toutes les donn√©es persistantes.
Utilisez-la uniquement si vous voulez repartir compl√®tement √† z√©ro ou pour votre premi√®re ex√©cution du stack.

   - Si ce script est modifi√© sous Windows (VS Code),
ex√©cuter `dos2unix start_stack.sh` avant de lancer le script

   ```bash
   cd src/docker
   docker volume prune -f
   docker image prune -a -f
   docker network prune -f
   docker container prune -f
   docker system prune -a -f --volumes
   docker-compose down --volumes --rmi all --remove-orphans
   docker buildx prune -a -f
   ```

   ```bash
   # Docker Desktop doit √™tre d√©marr√©
   # Depuis la racine du projet

   # WSL Ubuntu (terminal)
   cd src/docker
   chmod +x start_stack.sh
   ./start_stack.sh

   # Windows (PowerShell admin)
   cd src\docker
   Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass
   .\start_stack.ps1
   ```

---

## 5. Cr√©ation d‚Äôune vue et d‚Äôun tableau de bord dans ES/Kibana

### 5.1. Acc√®s √† ES/Kibana

   ```bash
   http://localhost:5601
   ```

### 5.2. V√©rification des donn√©es

Depuis ES/Kibana ‚Äì Dev Tools :

   ```bash
   # Liste tous les indices
   GET /_cat/indices?v
   # Voir le mapping d'un index
   GET /reviews/_mapping
   # Compter le nombre de documents
   GET /reviews/_count
   # R√©cup√©re tous les documents
   GET /reviews/_search
   {
      "query": {
         "match_all": {}
      }
   }
   # R√©cup√©re les 3 derni√®res reviews les plus r√©cents
   GET reviews/_search
   {
      "size": 3,
      "sort": [
         { "id_review": { "order": "desc" } }
      ]
   }
   ```

<img src="images/es-kibana_dev_tools.png" width="70%">

### 5.3. Cr√©ation d‚Äôune Data View

   ```bash
   Nom : NOV25_BDE_SATISFACTION_CLIENT
   Index pattern : reviews*
   Champ temporel : Aucun
   ```

### 5.4. Visualisation

1. Acc√©der √† Elastic/Kibana depuis le navigateur : http://localhost:5601/app/home#/

2. Aller dans **Visualize Library** ‚Üí **Create new visualization**

3. S√©lectionner le type de visualisation : **Lens**

4. Choisir la **Data View** pr√©c√©demment cr√©√©e (`NOV25_BDE_SATISFACTION_CLIENT`)

5. Cr√©er les visualisations suivantes :

   - **Histogramme des notes** (r√©partition des avis par score)
   - **Top cat√©gories** (cat√©gories les plus repr√©sent√©es)
   - **Volume d‚Äôavis** (nombre total d‚Äôavis ou √©volution)

6. Enregistrer chaque visualisation pour pouvoir les r√©utiliser dans un tableau de bord.

---

## 6. Acc√®s √† Streamlit

   ```bash
   http://localhost:8501
   ```

   - Identifiant  : admin</br>
   - Mot de passe : admin

<img src="images/streamlit_connexion.png" width="40%">

---

## 7. Acc√®s √† Apache Airflow

   ```bash
   http://localhost:8081/login/
   ```

   - Identifiant  : admin</br>
   - Mot de passe : admin

<img src="images/airflow_connexion.png" width="70%">
<img src="images/airflow_dag.png" width="70%">
<img src="images/airflow_graph.png" width="70%">

---

## 8. Acc√®s √† Prometheus/Grafana

- Prometheus :

   ```bash
   http://localhost:9090/targets
   ```

- Grafana :

   ```bash
   http://localhost:3000
   ```

   - Identifiant  : admin</br>
   - Mot de passe : admin

<img src="images/grafana_connexion.png" width="70%">
<img src="images/grafana_dashboard.png" width="70%">

---

## 9. Acc√®s √† FastAPI (docs)

- Prometheus :

   ```bash
   http://localhost:8000/docs
   ```

<img src="images/fastapi_docs.png" width="70%">

---

## 10. D√©pannage & probl√®mes fr√©quents

| Probl√®me                  | Cause probable                   | Solution                                               |
| ------------------------- | -------------------------------- | ----------------------------------------------------- |
| ES ne d√©marre pas          | Port 9200 utilis√©, m√©moire faible | V√©rifier ports et ajuster `docker-compose.yml`       |
| ConnectionError ES         | Service ES pas encore pr√™t       | Attendre 30s ou ajouter un retry                     |
| Mapping non appliqu√©       | Indice existant                  | Supprimer l‚Äôindice : `DELETE /reviews`              |
| Data View introuvable      | Mauvais pattern                  | V√©rifier que le pattern est `reviews*`              |
| Probl√®me de permissions    | Volume Docker                    | `chmod -R 777 ./data`                                |
| Docker sous Windows        | Docker Desktop ou WSL2 inactif   | V√©rifier Docker Desktop et WSL2, puis relancer      |
| Invalid char '/' config.json | `~/.docker/config.json` invalide | Supprimer tout commentaire et garder `{ "auths": {} }` |
| WSL + Docker login √©choue  | Credential helper mal configur√© | Supprimer entr√©es invalides, garder `{ "auths": {} }`, refaire `docker login` |
